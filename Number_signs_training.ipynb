{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Number_signs_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdulrahman-hassanin/numbers_signs_recognition/blob/master/Number_signs_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rak9evevq-Is",
        "colab_type": "code",
        "outputId": "a154a760-32b8-4334-8073-bc7cfcb0e116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNu-doImr0Ku",
        "colab_type": "text"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlcXf2T8_7gI",
        "colab_type": "code",
        "outputId": "9dfecf84-3be8-43c3-ad8e-38ee7abd6ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7cRU7dy_8Xs",
        "colab_type": "code",
        "outputId": "cc547638-b2b0-44e5-f939-700bb0e743d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls '/content/drive/My Drive/Colab Notebooks/Numbers Sign Dataset'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_signs.h5  train_signs.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N2Y_31UsDjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "def load_dataset():\n",
        "  train_dataset = h5py.File('/content/drive/My Drive/Colab Notebooks/Numbers Sign Dataset/train_signs.h5', 'r')\n",
        "  train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
        "  train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])\n",
        "  \n",
        "  test_dataset = h5py.File('/content/drive/My Drive/Colab Notebooks/Numbers Sign Dataset/test_signs.h5', 'r')\n",
        "  test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])\n",
        "  test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])\n",
        "  \n",
        "  classes = np.array(test_dataset[\"list_classes\"][:])\n",
        "  \n",
        "  train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "  test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "  \n",
        "  return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8x3bFz5vm3k",
        "colab_type": "code",
        "outputId": "84b512bc-b480-4be7-f580-dc84951534d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
        "\n",
        "# Normalization X\n",
        "X_train = X_train_orig / 255\n",
        "X_test = X_test_orig / 255\n",
        "\n",
        "# Conver Y into one_hot \n",
        "from keras.utils.np_utils import to_categorical\n",
        "Y_train = np.eye(6)[Y_train_orig.reshape(-1)]\n",
        "Y_test = np.eye(6)[Y_test_orig.reshape(-1)]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)\n",
        "print(Y_test_orig.shape)\n",
        "print(Y_test[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1080, 64, 64, 3)\n",
            "(120, 64, 64, 3)\n",
            "(1080, 6)\n",
            "(120, 6)\n",
            "(1, 120)\n",
            "[1. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXY41VrczcQW",
        "colab_type": "text"
      },
      "source": [
        "# Build ResNet50 Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcM3tLdh1CsX",
        "colab_type": "text"
      },
      "source": [
        "### 1.Identity Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS_yqcWEziye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "    \n",
        "    \n",
        "    #### main path\n",
        "    \n",
        "    # First component\n",
        "    X = Conv2D(filters=F1, kernel_size=(1,1), strides=(1,1), padding=\"valid\", name = conv_name_base + '2a')(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second Component\n",
        "    X = Conv2D(filters=F2, kernel_size=(f,f), strides=(1,1), padding = 'same', name = conv_name_base + '2b')(X)\n",
        "    X = BatchNormalization(axis=3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Third Component\n",
        "    X = Conv2D(filters=F3, kernel_size=(1,1), strides=(1,1), padding = 'valid', name = conv_name_base + '2c')(X)\n",
        "    X = BatchNormalization(axis=3, name= bn_name_base + '2c')(X)\n",
        "    \n",
        "    # Add shortcut\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmUWTa2e7bz0",
        "colab_type": "text"
      },
      "source": [
        "### The convolutional block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUisZxE17YSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s=2):\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a')(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b')(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component\n",
        "    X = Conv2D(F3, (1, 1), strides = (1, 1), name = conv_name_base + '2c')(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1,1), strides = (s, s), name = conv_name_base + '1')(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "\n",
        "    \n",
        "    return X "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0HngowU8bP7",
        "colab_type": "text"
      },
      "source": [
        "### ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uGtNV6a7g_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet50(input_shape = (64, 64, 30), classes=6):\n",
        "  \n",
        "  X_input = Input(input_shape)\n",
        "  \n",
        "      \n",
        "  # Zero-Padding\n",
        "  X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "  # Stage 1\n",
        "  X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1')(X)\n",
        "  X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "  # Stage 2\n",
        "  X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "  X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "  X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "  # Stage 3 \n",
        "  X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "  # Stage 4 \n",
        "  X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "  # Stage 5 \n",
        "  X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "  X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "  X = identity_block(X, 3, [512, 512, 2048], stage=5, block='d')\n",
        "\n",
        "  # AVGPOOL \n",
        "  X = AveragePooling2D(pool_size=(2,2),name = \"avg_pool\")(X)\n",
        "\n",
        "  # output layer\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(classes, activation='softmax', name='fc' + str(classes))(X)\n",
        "\n",
        "\n",
        "  # Create model\n",
        "  model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEv-2HzD9Nyn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "72d3f895-5ce9-4f1e-a13d-f9b128ac0a79"
      },
      "source": [
        "model = ResNet50(input_shape = (64, 64, 3), classes = 6)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLNt-Msr9t4u",
        "colab_type": "code",
        "outputId": "60cbe5f2-7e06-48c7-9f84-ae4f3b183da4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voPbtnZu_YeD",
        "colab_type": "code",
        "outputId": "9d8bc0e5-4589-44f3-b2a9-8f4408ffd069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        }
      },
      "source": [
        "model.fit(X_train, Y_train, epochs = 20, batch_size = 32)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/20\n",
            "1080/1080 [==============================] - 196s 182ms/step - loss: 3.6401 - acc: 0.2250\n",
            "Epoch 2/20\n",
            "1080/1080 [==============================] - 184s 170ms/step - loss: 2.0136 - acc: 0.4296\n",
            "Epoch 3/20\n",
            "1080/1080 [==============================] - 180s 167ms/step - loss: 0.8550 - acc: 0.7065\n",
            "Epoch 4/20\n",
            "1080/1080 [==============================] - 179s 166ms/step - loss: 0.8071 - acc: 0.7481\n",
            "Epoch 5/20\n",
            "1080/1080 [==============================] - 180s 167ms/step - loss: 0.4906 - acc: 0.8278\n",
            "Epoch 6/20\n",
            "1080/1080 [==============================] - 179s 166ms/step - loss: 0.2324 - acc: 0.9102\n",
            "Epoch 7/20\n",
            "1080/1080 [==============================] - 180s 166ms/step - loss: 0.1146 - acc: 0.9509\n",
            "Epoch 8/20\n",
            "1080/1080 [==============================] - 181s 167ms/step - loss: 0.1724 - acc: 0.9417\n",
            "Epoch 9/20\n",
            "1080/1080 [==============================] - 180s 166ms/step - loss: 0.1571 - acc: 0.9528\n",
            "Epoch 10/20\n",
            "1080/1080 [==============================] - 181s 168ms/step - loss: 0.1673 - acc: 0.9444\n",
            "Epoch 11/20\n",
            "1080/1080 [==============================] - 182s 168ms/step - loss: 0.1455 - acc: 0.9509\n",
            "Epoch 12/20\n",
            "1080/1080 [==============================] - 183s 170ms/step - loss: 0.0878 - acc: 0.9685\n",
            "Epoch 13/20\n",
            "1080/1080 [==============================] - 183s 169ms/step - loss: 0.0386 - acc: 0.9880\n",
            "Epoch 14/20\n",
            "1080/1080 [==============================] - 182s 169ms/step - loss: 0.0259 - acc: 0.9907\n",
            "Epoch 15/20\n",
            "1080/1080 [==============================] - 183s 169ms/step - loss: 0.0169 - acc: 0.9963\n",
            "Epoch 16/20\n",
            "1080/1080 [==============================] - 182s 169ms/step - loss: 0.0545 - acc: 0.9833\n",
            "Epoch 17/20\n",
            "1080/1080 [==============================] - 183s 169ms/step - loss: 0.0954 - acc: 0.9685\n",
            "Epoch 18/20\n",
            "1080/1080 [==============================] - 183s 170ms/step - loss: 0.0477 - acc: 0.9815\n",
            "Epoch 19/20\n",
            "1080/1080 [==============================] - 183s 170ms/step - loss: 0.0294 - acc: 0.9926\n",
            "Epoch 20/20\n",
            "1080/1080 [==============================] - 184s 170ms/step - loss: 0.0335 - acc: 0.9907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7b5296b320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08o6bbCp_hVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Numbers_signs_20epochs'+'.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHngRu-6CjBH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0814a715-409f-41dd-af8c-6c9c1c467432"
      },
      "source": [
        "preds = model.evaluate(X_test, Y_test)\n",
        "print(\"loss = \"+str(preds[0]))\n",
        "print(\"acc = \"+str(preds[1]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120/120 [==============================] - 2s 21ms/step\n",
            "loss = 0.2242736061414083\n",
            "acc = 0.9416666706403096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU3ElCfyegGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}